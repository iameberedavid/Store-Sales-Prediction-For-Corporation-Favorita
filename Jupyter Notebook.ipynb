{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b418d15f",
   "metadata": {},
   "source": [
    "# TIMESERIES ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fab111",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "This project focuses on the application of time series regression analysis to forecast sales for Corporation Favorita, a prominent grocery retailer based in Ecuador.\n",
    "\n",
    "The primary objective is to develop a robust model capable of accurately forecasting future sales by leveraging the extensive time series data of thousands of products sold across various Favorita locations. The resulting forecasts will provide valuable insights to the store's management, enabling them to formulate effective inventory and sales plans.\n",
    "\n",
    "Through this research, we will construct models based on historical analysis, establish scientific hypothesis using time-stamped historical data, and employ these models to observe patterns and guide strategic decision-making in the future. By delving into the data, our aim is to optimize operations and ultimately drive sales growth for Favorita Corporation, supporting the management team in extracting meaningful insights from their vast dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b03023",
   "metadata": {},
   "source": [
    "# Hypothesis\n",
    "\n",
    "Null Hypothesis: Sales are not affected by promotion, oil prices and holidays.\n",
    "\n",
    "Alternate Hypothesis: Sales are affected by promotion, oil prices and holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f35455",
   "metadata": {},
   "source": [
    "# Analytical Questions\n",
    "\n",
    "1. Is the train dataset complete (has all the required dates)?\n",
    "\n",
    "2. Which dates have the lowest and highest sales for each year?\n",
    "\n",
    "3. Did the earthquake impact sales?\n",
    "\n",
    "4. Are certain groups of stores selling more products? (Cluster, city, state, type)\n",
    "\n",
    "5. Are sales affected by promotions, oil prices and holidays?\n",
    "\n",
    "6. What analysis can we get from the date and its extractable features?\n",
    "\n",
    "7. What is the difference between RMSLE, RMSE, MSE (or why is the MAE greater than all of them?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cd3d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries to create connection string to SQL server\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Library for imputing missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Library for modelling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Library for working with operating system\n",
    "import os\n",
    "\n",
    "# Library to handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "829015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.rc(\n",
    "    \"figure\",\n",
    "    autolayout=True,\n",
    "    figsize=(11, 4),\n",
    "    titlesize=18,\n",
    "    titleweight='bold',\n",
    ")\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=16,\n",
    "    titlepad=10,\n",
    ")\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    "    legend=False,\n",
    ")\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c76e14",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "### Accessing and loading the datasets\n",
    "\n",
    "The first dataset was collected from a SQL database by first passing a connection string using the pyodbc library. Afterwards a SQL query was used to obtain the dataset. This is as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93b7ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variable in the .env file into a dictionary\n",
    "\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the .env file\n",
    "server = environment_variables.get('SERVER')\n",
    "database = environment_variables.get('DATABASE')\n",
    "username = environment_variables.get('USERNAME')\n",
    "password = environment_variables.get('PASSWORD')\n",
    "\n",
    "# The connection string is an f string that includes all the variable above to establish a connection to the server.\n",
    "connection_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a79cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library to pass in the connection string.\n",
    "# Check your internet connection if it takes more time than necessary.\n",
    "\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "# Get the oil dataset using the SQL query shown below\n",
    "query1 = 'Select * from dbo.oil'\n",
    "oil = pd.read_sql(query1, connection)\n",
    "\n",
    "# Get the holiday dataset using the SQL query shown below\n",
    "query2 = 'Select * from dbo.holidays_events'\n",
    "holiday = pd.read_sql(query2, connection)\n",
    "\n",
    "# Get the stores dataset using the SQL query shown below\n",
    "query3 = 'Select * from dbo.stores'\n",
    "stores = pd.read_sql(query3, connection)\n",
    "\n",
    "# Save the datasets\n",
    "oil.to_csv(r'oil.csv')\n",
    "holiday.to_csv(r'holiday.csv')\n",
    "stores.to_csv(r'stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57598695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the other datasets\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "transactions = pd.read_csv('transactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d681dc",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ba797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the holiday dataset\n",
    "\n",
    "holiday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the holiday dataset\n",
    "\n",
    "holiday.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a1598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the holiday dataset\n",
    "\n",
    "holiday.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the oil dataset\n",
    "\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the oil dataset\n",
    "\n",
    "oil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the missing values in the oil datast\n",
    "\n",
    "oil.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the oil dataset\n",
    "\n",
    "oil.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the stores dataset\n",
    "\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the holiday dataset\n",
    "\n",
    "stores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the stores dataset\n",
    "\n",
    "stores.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the sample_submission dataset\n",
    "\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf91928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the sample_submission dataset\n",
    "\n",
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab49ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the sample_submission dataset\n",
    "\n",
    "sample_submission.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36820f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the test dataset\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the test dataset\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the test dataset\n",
    "\n",
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62956307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the train dataset\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4614189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the datatypes of the columns in the train dataset\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the train dataset\n",
    "\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76607324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the train dataset\n",
    "\n",
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the first five rows of the transactions dataset\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ba1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and the datatypes of the columns in the transactions dataset\n",
    "\n",
    "transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates on the transactions dataset\n",
    "\n",
    "transactions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3cf4ba",
   "metadata": {},
   "source": [
    "# Problems Identified\n",
    "\n",
    "The oil dataset has 43 missing values on the 'dcoilwtico' column.\n",
    "\n",
    "For all the datasets that have a 'date' column, the 'date' column is present as object datatype instead of datetime datatype.\n",
    "\n",
    "The datasets are seperate, and need to be merged together for better analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a92d6",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The problems identified with the datasets will be handled to prepare the data for analysis and modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ddc5e",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the SimpleImputer class with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# fit the imputer to the 'dcoilwtico' column of oil dataset\n",
    "imputer.fit(oil[['dcoilwtico']])\n",
    "\n",
    "# Impute missing values on the 'dcoilwtico' column of oil dataset with the imputer\n",
    "oil['dcoilwtico'] = imputer.transform(oil[['dcoilwtico']])\n",
    "\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b4579",
   "metadata": {},
   "source": [
    "### Combine the datasets based on common columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c11a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge transactions dataset to train on 'date' and 'store_nbr' columns\n",
    "df1 = pd.merge(train, transactions, on=['date', 'store_nbr'])\n",
    "\n",
    "# Merge holiday dataset to df1 on 'date' column\n",
    "df2 = pd.merge(df1, holiday, on='date')\n",
    "\n",
    "# Merge oil dataset to df2 on 'date' column\n",
    "df3 = pd.merge(df2, oil, on='date')\n",
    "df3\n",
    "\n",
    "# Merge store dataset to df3 on 'store_nbr' column\n",
    "df4 = pd.merge(df3, stores, on='store_nbr')\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e11af",
   "metadata": {},
   "source": [
    "### Change the datatype of the 'date' column from object to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['date'] = pd.to_datetime(df4['date'])\n",
    "\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54b961",
   "metadata": {},
   "source": [
    "The missing values in the 'dcoilwtico' column of the oil dataset have been filled, the datasets have been merged and the datatype of the 'date' column has been changed from object to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating 'type_x' column on df4\n",
    "\n",
    "df4['type_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating 'type_y' column on df4\n",
    "\n",
    "df4['type_y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'type_x' and type_y' to 'holiday_type' and 'store_type' respectively\n",
    "\n",
    "df4 = df4.rename(columns={'type_x': 'holiday_type', 'type_y': 'store_type'})\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename df4 to train_data and save the DataFrame\n",
    "\n",
    "train_merged = df4\n",
    "train_merged.to_csv(r'train_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for numerical columns in train_data DataFrame\n",
    "\n",
    "train_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot of the 'transactions' column grouped by 'locale'\n",
    "sns.boxplot(x='transactions', y='locale', data=train_merged)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot of transactions by City\n",
    "sns.barplot(x='transactions', y='city', data=train_merged)\n",
    "\n",
    "width=0.5,  # Adjust the width of the boxes\n",
    "fliersize=3, # Adjust the size of the outliers\n",
    "showmeans=True, # Show the mean value\n",
    "meanline=True, # Show a line for the mean\n",
    "notch=True, # Make the boxes \"notched\"\n",
    "\n",
    "# Add a title and labels for the x and y axis\n",
    "plt.title('Transactions by City', fontsize=18)\n",
    "plt.xlabel('Frequency', fontsize=16)\n",
    "plt.ylabel('City', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c350c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the 'transactions' column\n",
    "train_merged.transactions.hist()\n",
    "\n",
    "# Add labels to the x-axis, y-axis, and title\n",
    "plt.xlabel('Transactions', fontsize=16)\n",
    "plt.ylabel('Frequency', fontsize=16)\n",
    "plt.title('Histogram of Transactions', fontsize=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7eaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of train_data with numerical columns only\n",
    "train_merged_num = train_merged.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix of the numerical columns\n",
    "corr_matrix = train_merged_num.corr()\n",
    "\n",
    "# Visualizing the correlation matrix with a heatmap\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "\n",
    "# Save the chart as an image file\n",
    "# plt.savefig('Correlation of the numerical columns of the train dataset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features from the 'date' column\n",
    "\n",
    "train_merged['year'] = train_merged.date.dt.year\n",
    "train_merged['month'] = train_merged.date.dt.month\n",
    "train_merged['dayofmonth'] = train_merged.date.dt.day\n",
    "train_merged['dayofweek'] = train_merged.date.dt.dayofweek\n",
    "train_merged['dayname'] = train_merged.date.dt.strftime('%A')\n",
    "\n",
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random sample of 8 rows\n",
    "\n",
    "train_merged.sample(8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42636ad2",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83920497",
   "metadata": {},
   "source": [
    "# Answering Analytical Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7cbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
